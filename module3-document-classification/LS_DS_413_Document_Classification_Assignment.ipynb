{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_413_Document_Classification_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrokenShell/DS-Unit-4-Sprint-1-NLP/blob/master/module3-document-classification/LS_DS_413_Document_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IyX0OcnbVR-s"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PjmpM6GtVR-w"
      },
      "source": [
        "# Document Classification (Assignment)\n",
        "\n",
        "This notebook is for you to practice skills during lecture.\n",
        "\n",
        "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today's all about having fun and practicing your skills.\n",
        "\n",
        "## Sections\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
        "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fpw62f6rVR-x"
      },
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hpF5jyVIVR-y",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VJfrhUC6VR-0"
      },
      "source": [
        "### Load Competition Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5I1YAm47VR-1",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/BrokenShell/DS-Unit-4-Sprint-1-NLP/master/module3-document-classification/data/train.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/BrokenShell/DS-Unit-4-Sprint-1-NLP/master/module3-document-classification/data/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L_LoDIq4VR-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9862b6ee-20ea-43cd-fd9e-1083c52704f5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1321</td>\n",
              "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3861</td>\n",
              "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>655</td>\n",
              "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>555</td>\n",
              "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1965</td>\n",
              "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                        description  ratingCategory\n",
              "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
              "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
              "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
              "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
              "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yexHE9mOVR-_"
      },
      "source": [
        "### Define Pipeline Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-lO0YcUyOXPl",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_yfHb8-VR_A",
        "colab": {}
      },
      "source": [
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "pipe = Pipeline([('vect', vect), ('clf', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VoDXpFWnVR_E"
      },
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYDM5gh2VR_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "06c3b893-bab7-4f8f-fac6-9dbdff35dadb"
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': ( 0.75, 1.0),\n",
        "    'vect__min_df': (.02, .05),\n",
        "    'vect__max_features': (500,1000),\n",
        "    'clf__n_estimators':(5, 10,),\n",
        "    'clf__max_depth':(15,20)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=8, verbose=1)\n",
        "grid_search.fit(train['description'], train['ratingCategory'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=8)]: Done 160 out of 160 | elapsed:   17.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 2),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=8,\n",
              "             param_grid={'clf__max_depth': (15, 20),\n",
              "                         'clf__n_estimators': (5, 10),\n",
              "                         'vect__max_df': (0.75, 1.0),\n",
              "                         'vect__max_features': (500, 1000),\n",
              "                         'vect__min_df': (0.02, 0.05)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PTosxabeVR_J"
      },
      "source": [
        "### Make a Submission File\n",
        "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zw1JzFGQVR_K",
        "colab": {}
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g0jImMf0N40n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fb32755-0af4-4e22-ceee-d4bd424dbddc"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7193549062854441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CRbnrgpBVR_N",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iAub7K2qVR_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5a3591e4-d0df-41ac-a165-4de2bccdc580"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KStGs5y-VR_V",
        "colab": {}
      },
      "source": [
        "subNumber = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZrLTx0kJVR_Y",
        "colab": {}
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lTkd5KHxVR_b"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve a minimum of 70% Accuracy on your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iFMDsheWVR_c"
      },
      "source": [
        "## Latent Semantic Indexing (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJoOpDFRg8ig",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['alt.atheism', 'talk.religion.misc']\n",
        "data = fetch_20newsgroups(subset='train', categories=categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pwx7aLXGStQ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "a8cfe051-5831-47a0-8a0f-fd24707a8815"
      },
      "source": [
        "svd = TruncatedSVD(n_components=100, algorithm='randomized', n_iter=10)\n",
        "\n",
        "params = { \n",
        "    'lsi__svd__n_components': [10, 100, 250],\n",
        "    'lsi__vect__max_df': [0.9, 0.95, 1.0],\n",
        "    'clf__n_estimators': [5, 10, 20],\n",
        "}\n",
        "\n",
        "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
        "\n",
        "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=8, verbose=1)\n",
        "grid_search.fit(data.data, data.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=8)]: Done 135 out of 135 | elapsed:  8.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('lsi',\n",
              "                                        Pipeline(memory=None,\n",
              "                                                 steps=[('vect',\n",
              "                                                         TfidfVectorizer(analyzer='word',\n",
              "                                                                         binary=False,\n",
              "                                                                         decode_error='strict',\n",
              "                                                                         dtype=<class 'numpy.float64'>,\n",
              "                                                                         encoding='utf-8',\n",
              "                                                                         input='content',\n",
              "                                                                         lowercase=True,\n",
              "                                                                         max_df=1.0,\n",
              "                                                                         max_features=None,\n",
              "                                                                         min_df=1,\n",
              "                                                                         ngram_range=(1,\n",
              "                                                                                      2),\n",
              "                                                                         norm='l2',\n",
              "                                                                         preprocessor=None,\n",
              "                                                                         smooth_...\n",
              "                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                               n_estimators=100,\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=8,\n",
              "             param_grid={'clf__n_estimators': [5, 10, 20],\n",
              "                         'lsi__svd__n_components': [10, 100, 250],\n",
              "                         'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X04ZatS_WwW4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13e42456-437c-4f8b-bb6c-8ae2ddfeb971"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9066231470148238"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c0U5o35-VR_d",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35LutzYwVR_0"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmApnr2GVR_e"
      },
      "source": [
        "### Define Pipeline Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6cm5UC3qVR_f",
        "colab": {}
      },
      "source": [
        "svd = TruncatedSVD(n_components=100, algorithm='randomized', n_iter=10)\n",
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
        "\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dKFCLNMWVR_k"
      },
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rw-OTKRRVR_l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "c425b1cd-a20b-4d75-ae9f-71b552e0d9f9"
      },
      "source": [
        "parameters = {\n",
        "    'lsi__svd__n_components': [10, 100, 250],\n",
        "    'lsi__vect__max_df': (0.75, 1.0),\n",
        "    'clf__max_depth': (5, 10, 15, 20),\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=8, verbose=1)\n",
        "grid_search.fit(train['description'], train['ratingCategory'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=8)]: Done 120 out of 120 | elapsed:  8.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('lsi',\n",
              "                                        Pipeline(memory=None,\n",
              "                                                 steps=[('vect',\n",
              "                                                         TfidfVectorizer(analyzer='word',\n",
              "                                                                         binary=False,\n",
              "                                                                         decode_error='strict',\n",
              "                                                                         dtype=<class 'numpy.float64'>,\n",
              "                                                                         encoding='utf-8',\n",
              "                                                                         input='content',\n",
              "                                                                         lowercase=True,\n",
              "                                                                         max_df=1.0,\n",
              "                                                                         max_features=None,\n",
              "                                                                         min_df=1,\n",
              "                                                                         ngram_range=(1,\n",
              "                                                                                      2),\n",
              "                                                                         norm='l2',\n",
              "                                                                         preprocessor=None,\n",
              "                                                                         smooth_...\n",
              "                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                               n_estimators=100,\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=8,\n",
              "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
              "                         'lsi__svd__n_components': [10, 100, 250],\n",
              "                         'lsi__vect__max_df': (0.75, 1.0)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5WtjNjYAVR_p"
      },
      "source": [
        "### Make a Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TSrF3XoeVR_q",
        "colab": {}
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gjUiZ4qVR_s",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AK7rknDGVR_v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "71441a9f-5847-488d-dd51-9a35965106d7"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AH7Q13NeVR_y",
        "colab": {}
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HHCschCfVSAI"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Make a submission to Kaggle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jSJjxVyaVR_1"
      },
      "source": [
        "# Word Embeddings with Spacy (Learn)\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hu6mrUCX6mV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "07c23ba0-3bf4-4782-9265-4dc1568906c2"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from en_core_web_lg==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.7.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.24.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.46.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.25.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AYRsj01g6Ihm",
        "colab": {}
      },
      "source": [
        "# if this cell wont run - restart the runtime!\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KD7rgeJo_qq3",
        "colab": {}
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRYoKCWWHCWI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7f17323b-bbb9-4981-a944-65807788e4ec"
      },
      "source": [
        "!pip install IteratorAlgorithms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: IteratorAlgorithms in /Users/SpiritHome/PycharmProjects/DS-Unit-4-Sprint-1-NLP/venv/lib/python3.8/site-packages (0.1.4)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MshiUN33HGRf",
        "colab": {}
      },
      "source": [
        "import IteratorAlgorithms as ia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PLRzD_eRHWHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ae6b5ee-f77d-49a9-f8a2-39724eaaba5e"
      },
      "source": [
        "param_dist = {\n",
        "    'max_depth' : [4, 8, 16, 32, None],\n",
        "    'min_samples_leaf' : [1, 2, 4, 6],\n",
        "    'max_features': [6, 9, 12, 'auto']\n",
        "}\n",
        "iterations = ia.product(len(n) for n in param_dist.values())\n",
        "print(iterations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mRacR5sXVR_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "fd67934b-34ac-4d1b-d79f-444a4c535f9d"
      },
      "source": [
        "clf = RandomForestClassifier(random_state=42, n_jobs=8)\n",
        "X = get_word_vectors(train['description'])\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    clf, \n",
        "    param_dist, \n",
        "    cv=5, \n",
        "    n_jobs=-1, \n",
        "    verbose=10, \n",
        "    random_state=42, \n",
        "    n_iter=iterations,\n",
        ").fit(X, train['ratingCategory'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   15.2s\n",
            "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   21.1s\n",
            "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   25.1s\n",
            "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   30.1s\n",
            "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   34.8s\n",
            "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   39.2s\n",
            "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   45.0s\n",
            "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   53.2s\n",
            "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   58.9s\n",
            "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_bi1btHrFfvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8029ee08-2620-42ee-a21f-47a4f7faf7ff"
      },
      "source": [
        "print(search.best_params_)\n",
        "print(search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 16}\n",
            "0.7355028983729011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KFwi2rXBVR_8"
      },
      "source": [
        "### Make a Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFdUtDtUVR_9",
        "colab": {}
      },
      "source": [
        "# Predictions on test sample\n",
        "pred = search.predict(get_word_vectors(test['description']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7MVMvgQVSAA",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ldK1bnS7VSAC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3d733f73-897d-473f-ace6-3ee698b9a799"
      },
      "source": [
        "# Make Sure the Category is an Integer\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h9T8jsuVVSAF",
        "colab": {}
      },
      "source": [
        "# Save your Submission File\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
        "subNumber += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cZOIDDxFVSAJ"
      },
      "source": [
        "# Post Lecture Assignment\n",
        "<a id=\"p4\"></a>\n",
        "\n",
        "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
        "\n",
        "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
        "    - What is \"Sentiment Analysis\"? \n",
        "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
        "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
        "    - What are common applications of sentiment analysis?\n",
        "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
        "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
        "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
      ]
    }
  ]
}